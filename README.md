To start benchmark:
```
export WORKDIR=/home/user/workspace
docker pull 140.96.29.39:5000/myelintek/mlmonkey:latest
docker run -it --runtime nvidia -v $WORKDIR:/workspace -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/Imagenet:/tfrecords -e WORKDIR=$WORKDIR 140.96.29.39:5000/myelintek/mlmonkey:latest
```
Make sure there is enough disk space, script will download COCO and Translator datasets automatically.
Imagenet should be in tfrecords format.

===========================================================================================================================

Main running script is located in `scripts/run.sh`. It is copied to `/scripts/run.sh` when buildind docker image.

Benchmark logs are saved in `/workspace/logs`. `/workspace` directory should be mounted insied docker container, so all the files will persist after container is deleted.

Logs for finding max possible batch size are saved in `/tmp/log/` (this logs are useless for user, saved for debugging purpose).

Webpage file `index.html` is located in `scripts/index.html` and copied to `/web/index.html` when buildind docker image.

Folder structure for webpage should look like this:
```
/web/   index.html                        - copied when building image
        spec.html                         - generated when starting run.sh, contains output of lshw     
        csv/         time/      ***.csv   - parsed benchmark logs with running time
                                ***.csv 
                     img_sec/   ***.csv   - parsed benchmark logs with images/second
                                ***.csv
        hw_logs/     p2p.log              - hardware logs generated by script
                     nvidia-smi.log
                     topology.log
                 
```

After script finishes whole `/web` folder is copied in `/workspace/logs/web`, so user can see visualization and hardware logs of older runs.
